# T5 Claim Normalization

A T5-based claim normalization model for processing and normalizing social media posts.

## ğŸš€ Features
- Fine-tunes a **T5 model** on a dataset of social media posts.
- **Tokenizes** and **trains** using the `transformers` library.
- Evaluates performance using the **METEOR score**.
- Includes an **interactive testing script**.

---

## ğŸ“¦ Installation

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/hafidelmoudden/t5_claim_normalization.git
cd t5_claim_normalization
```

### 2ï¸âƒ£ Create a Virtual Environment (Optional)
```bash
python -m venv venv
source venv/bin/activate  # On macOS/Linux
venv\Scripts\activate     # On Windows
```

### 3ï¸âƒ£ Install Dependencies
```bash
pip install .
```

---

## ğŸ“œ Usage

### ğŸ”¹ Train the Model
```bash
train
```
This will:
- Load the dataset (`data/train-eng.csv` & `data/dev-eng.csv`).
- Train the model using `transformers.Trainer`.
- Save the final model to `model_result/t5_claim_normalization`.

### ğŸ”¹ Evaluate the Model
```bash
evaluate
```
This will:
- Load the trained model.
- Generate predictions on the **dev set**.
- Compute the **METEOR score**.

### ğŸ”¹ Test the Model (Interactive CLI)
```bash
test_model
```
You can enter a **social media post**, and the model will return a **normalized claim**.

---

## ğŸ“‚ Project Structure
```
t5_claim_normalization/
â”‚â”€â”€ data/                          # Directory for datasets
â”‚   â”œâ”€â”€ train-eng.csv              # Training dataset
â”‚   â”œâ”€â”€ dev-eng.csv                # Development dataset
â”‚
â”‚â”€â”€ model/                         # Directory containing the trained model
â”‚   â”œâ”€â”€ added_tokens.json
â”‚   â”œâ”€â”€ config.json
â”‚   â”œâ”€â”€ generation_config.json
â”‚   â”œâ”€â”€ model_test.py              # Interactive testing script
â”‚   â”œâ”€â”€ model.safetensors          # Trained model weights
â”‚   â”œâ”€â”€ special_tokens_map.json
â”‚   â”œâ”€â”€ spiece.model
â”‚   â”œâ”€â”€ tokenizer_config.json
â”‚
â”‚â”€â”€ t5_claim_normalization/        # Directory containing the scripts
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ evaluate_meteor.py
â”‚   â”œâ”€â”€ model_test.py
â”‚   â”œâ”€â”€ run_training.py             
â”‚
â”‚â”€â”€ pyproject.toml                 # Project metadata and dependencies
â”‚â”€â”€ README.md                      # Documentation
â”‚â”€â”€ requirements.txt               # List of required dependencies
â”‚â”€â”€ run_training.py                # Model training script
```

---

## âš™ï¸ Dependencies
- `numpy`
- `pandas`
- `datasets`
- `transformers`
- `torch`
- `nltk`
- `sentencepiece`
- `accelerate`

Install manually with:
```bash
pip install numpy pandas datasets transformers torch nltk sentencepiece accelerate
```

---